{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8834a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import models\n",
    "import torch\n",
    "from utils import accuracy\n",
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b9e71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.__dict__['resnet32'](num_classes=10, use_norm=False)\n",
    "checkpoint = torch.load('checkpoint/cifar10_resnet32_CE_None_exp_0.01_0/ckpt.best.pth.tar', map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3f37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(val_loader, model, flag='val'):\n",
    "    # switch to evaluate mode\n",
    "\n",
    "    model.eval()\n",
    "    model = model.cuda(0)\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if 0 is not None:\n",
    "                input = input.cuda(0, non_blocking=True)\n",
    "            target = target.cuda(0, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "            # measure elapsed time\n",
    "\n",
    "            _, pred = torch.max(output, 1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "        cf = confusion_matrix(all_targets, all_preds).astype(float)\n",
    "        cls_cnt = cf.sum(axis=1)\n",
    "        cls_hit = np.diag(cf)\n",
    "        cls_acc = cls_hit / cls_cnt\n",
    "        output = ('{flag} Results: Prec@1 {acc1:.3f} Prec@5 {acc5:.3f}'\n",
    "                  .format(flag=flag, acc1=acc1.item(), acc5=acc5.item()))\n",
    "        out_cls_acc = '%s Class Accuracy: %s' % (\n",
    "            flag, (np.array2string(cls_acc, separator=',', formatter={'float_kind': lambda x: \"%.3f\" % x})))\n",
    "        print(output)\n",
    "        print(out_cls_acc)\n",
    "\n",
    "    return cf, acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7cc164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "val Results: Prec@1 57.000 Prec@5 92.000\n",
      "val Class Accuracy: [0.914,0.791,0.748,0.778,0.829,0.253,0.363,0.207,0.315,0.126]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=100, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "\n",
    "cf, _ = validate(val_loader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bbf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.copy(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84528fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a - np.diag(a) * np.identity(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0dae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.argmax(a[-3:,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5f0872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.,   0.,  78., 211., 451.,  27.,   2.,   0.,   1.,   0.],\n",
       "       [524.,   9.,  29.,  66.,  48.,   0.,   9.,   0.,   0.,   0.],\n",
       "       [296., 155.,  45., 158., 161.,   5.,   3.,   2.,  49.,   0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e9f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f4d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tails = np.asarray([78, 79, 88, 89, 98, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3077fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp[tails-70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3febdb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 44, 50,  8,  2, 61])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d345fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940837a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2845f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c1bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "0 8\n",
      "Files already downloaded and verified\n",
      "1000\n",
      "(10, 100)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "tail_to_head = {'cifar10': {7:4, 8:0, 9:0},'cifar100':{78:18, 79:44, 88:50, 89:8, 98:2, 99:61}}\n",
    "new_tail_to_head = {'cifar10': {8:0},'cifar100':{78:18, 79:44, 88:50, 89:8, 98:2, 99:61}}\n",
    "t_to_h_list = []\n",
    "model = models.__dict__['resnet32'](num_classes=10, use_norm=False)\n",
    "checkpoint = torch.load('checkpoint/cifar10_resnet32_CE_None_exp_0.1_0/ckpt.best.pth.tar', map_location='cuda:0')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "model = model.cuda(0)\n",
    "for tail in new_tail_to_head['cifar10'].keys():\n",
    "    train = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "#     tail = 8\n",
    "    head= new_tail_to_head['cifar10'][tail]\n",
    "    print(head, tail)\n",
    "    idx = [i for i, item in enumerate(train.targets) if item==head]\n",
    "    idx = np.array(idx)\n",
    "    train = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    train.targets = [train.targets[i] for i in idx]\n",
    "    train.data = [train.data[i] for i in idx]\n",
    "    print(len(train.data))\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=100, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(loader):\n",
    "            if 0 is not None:\n",
    "                input = input.cuda(0, non_blocking=True)\n",
    "            target = target.cuda(0, non_blocking=True)\n",
    "            # compute output\n",
    "            output = model(input).cpu().numpy()[:, tail]\n",
    "            preds.append(output)\n",
    "    preds = np.array(preds)\n",
    "    print(preds.shape)\n",
    "    preds = np.hstack(preds)\n",
    "    print(preds.shape)\n",
    "    inds = np.flip(np.argsort(preds))\n",
    "    arr = preds[inds]\n",
    "    all_list = np.stack([inds, arr])\n",
    "    t_to_h_list.append({'head':head, 'tail':tail, 'samples':all_list})\n",
    "import pickle\n",
    "with open('./data/new_cifar10_resnet32_CE_None_exp_0.1_0.pickle', 'wb') as f:\n",
    "    pickle.dump(t_to_h_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4dae9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c8677a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3335ed77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab2153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d692f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5fa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
